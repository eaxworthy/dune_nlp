{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist, sent_tokenize\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/prepared_texts/dune.txt') as file:\n",
    "    dune_text = file.read()\n",
    "with open('data/prepared_texts/sandworms_clean.txt', encoding=\"utf8\", mode='r') as file:\n",
    "    worm_text = file.read()\n",
    "\n",
    "summary_df = pd.DataFrame(index=['Dune', 'Worms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dune_split = nltk.sent_tokenize(dune_text)\n",
    "dune_words = [nltk.word_tokenize(sent) for sent in dune_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm_split = nltk.sent_tokenize(worm_text)\n",
    "worm_words = [nltk.word_tokenize(sent) for sent in worm_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['Num. Sentences'] = [len(dune_words), len(worm_words)]\n",
    "dune_sent_len = sum([len(i) for i in dune_words])/len(dune_words)\n",
    "worm_sent_len = sum([len(i) for i in worm_words])/len(worm_words)\n",
    "summary_df['Avg. Sentence Len'] = [dune_sent_len, worm_sent_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num. Sentences</th>\n",
       "      <th>Avg. Sentence Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dune</th>\n",
       "      <td>17668</td>\n",
       "      <td>13.420874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worms</th>\n",
       "      <td>9448</td>\n",
       "      <td>17.989733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Num. Sentences  Avg. Sentence Len\n",
       "Dune            17668          13.420874\n",
       "Worms            9448          17.989733"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('A', 'DT'), ('beginning', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('time', 'NN'), ('for', 'IN'), ('taking', 'VBG'), ('the', 'DT'), ('most', 'RBS'), ('delicate', 'JJ'), ('care', 'NN'), ('that', 'IN'), ('the', 'DT'), ('balances', 'NNS'), ('are', 'VBP'), ('correct', 'JJ'), ('.', '.')], [('This', 'DT'), ('every', 'DT'), ('sister', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Bene', 'NNP'), ('Gesserit', 'NNP'), ('knows', 'VBZ'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "dune_tagged = [nltk.pos_tag(tokens) for tokens in dune_words]\n",
    "print(dune_tagged[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('So', 'RB'), ('many', 'JJ'), ('people', 'NNS'), ('I', 'PRP'), ('knew', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('past', 'NN'), ('are', 'VBP'), ('not', 'RB'), ('yet', 'RB'), ('reborn', 'VBN'), ('.', '.')], [('I', 'PRP'), ('still', 'RB'), ('miss', 'VB'), ('them', 'PRP'), (',', ','), ('even', 'RB'), ('though', 'IN'), ('I', 'PRP'), ('do', 'VBP'), ('not', 'RB'), ('remember', 'VB'), ('them', 'PRP'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "worm_tagged = [nltk.pos_tag(tokens) for tokens in worm_words]\n",
    "print(worm_tagged[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing - Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_adjph = \"ADJPH: {<RB.?>+<JJ.?>}\"\n",
    "chunk_parser_adj = nltk.RegexpParser(grammar_adjph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 28 adjectives that occur in both text's top 50 adjectives are:  ['own', 'old', 'other', 'more', 'many', 'dead', 'such', 'new', 'little', 'open', 'first', 'good', 'much', 'young', 'deep', 'long', 'few', 'full', 'great', 'small', 'same', 'entire', 'last', 'true', 'possible', 'human', 'enough', 'real']\n",
      "There are 22 unique adjectives for Dune:  ['black', 'right', 'sure', 'silent', 'left', 'low', 'sudden', 'dark', 'certain', 'terrible', 'high', 'green', 'dry', 'dangerous', 'clear', 'white', 'strange', 'wide', 'subtle', 'yellow', 'obvious', 'big']\n",
      "There are 22 unique adjectives for Sandworms of Dune:  ['no-ship', 'original', 'large', 'll', 'past', 'Duncan', 'least', 'ready', 'most', 'different', 'able', 'necessary', 'final', 'thinking-machine', 'us.', 'greater', 'whole', 've', 'independent', 'only', 'huge', 'next']\n"
     ]
    }
   ],
   "source": [
    "#adjectives\n",
    "dune_adjective_tokens = []\n",
    "for sentence in dune_tagged:\n",
    "    for word, pos in sentence:\n",
    "        if pos in ['JJ', 'JJR', 'JJS']: \n",
    "            if len(word)>1:\n",
    "                dune_adjective_tokens.append(word)\n",
    "dune_freq_adjective = nltk.FreqDist(dune_adjective_tokens)\n",
    "\n",
    "worm_adjective_tokens = []\n",
    "for sentence in worm_tagged:\n",
    "    for word, pos in sentence:\n",
    "        if pos in ['JJ', 'JJR', 'JJS']: \n",
    "            if len(word)>1:\n",
    "                worm_adjective_tokens.append(word)\n",
    "worm_freq_adjective = nltk.FreqDist(worm_adjective_tokens)\n",
    "summary_df['Num. Adjectives'] = [len(dune_adjective_tokens), len(worm_adjective_tokens)]\n",
    "\n",
    "dune_adjs = [word for word, freq in dune_freq_adjective.most_common(50)]\n",
    "worm_adjs = [word for word, freq in worm_freq_adjective.most_common(50)]\n",
    "shared_adjs = [word for word in dune_adjs if word in worm_adjs]\n",
    "print(f'The {len(shared_adjs)} adjectives that occur in both text\\'s top 50 adjectives are: ', shared_adjs)\n",
    "dune_unq_adjs = [word for word in dune_adjs if word not in worm_adjs]\n",
    "worm_unq_adjs = [word for word in worm_adjs if word not in dune_adjs]\n",
    "print(f'There are {len(dune_unq_adjs)} unique adjectives for Dune: ', dune_unq_adjs)\n",
    "print(f'There are {len(worm_unq_adjs)} unique adjectives for Sandworms of Dune: ', worm_unq_adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dune_adjph_tags = []\n",
    "for sent in dune_tagged:\n",
    "    if len(sent) > 0:\n",
    "        tree = chunk_parser_adj.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'ADJPH':\n",
    "                dune_adjph_tags.append(subtree)     \n",
    "\n",
    "dune_adjective_phrases = []\n",
    "for sent in dune_adjph_tags:\n",
    "    temp = ''\n",
    "    for w, t in sent:\n",
    "        temp += w+ ' '    \n",
    "    dune_adjective_phrases.append(temp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm_adjph_tags = []\n",
    "for sent in worm_tagged:\n",
    "    if len(sent) > 0:\n",
    "        tree = chunk_parser_adj.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'ADJPH':\n",
    "                worm_adjph_tags.append(subtree)\n",
    "                \n",
    "worm_adjective_phrases = []\n",
    "for sent in worm_adjph_tags:\n",
    "    temp = ''\n",
    "    for w, t in sent:\n",
    "        temp += w+ ' '    \n",
    "    worm_adjective_phrases.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Freqeuncy Distributions\n",
    "dune_freq_adjph = FreqDist(dune_adjective_phrases)\n",
    "worm_freq_adjph = FreqDist(worm_adjective_phrases)\n",
    "\n",
    "\n",
    "#Store in DataFrame\n",
    "adjs_df = pd.DataFrame({'dune_adjph': dune_freq_adjph.most_common(50), \\\n",
    "    'dune_adjs': dune_freq_adjective.most_common(50),\\\n",
    "    'worms_adjph': worm_freq_adjph.most_common(50),\\\n",
    "    'worms_adjs': worm_freq_adjective.most_common(50)})\n",
    "summary_df['Num. AdjPh'] = [len(dune_adjph_tags), len(worm_adjph_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 11 adjective phrases that occur in both text's top 50 adjective phrases are:  ['so many ', 'too much ', 'so much ', 'So many ', 'so little ', 'too late ', 'little more ', 'not necessary ', 'no longer ', 'more important ', 'very little ']\n",
      "There are 39 unique adjective phrases for Dune:  ['as much ', 'not sure ', 'most precious ', 'precisely correct ', 'most dangerous ', 'so young ', 'so few ', 'not likely ', 'so dark ', 'So much ', 'so low ', 'Very good ', 'not good ', 'so sure ', 'Too much ', 'Too bad ', 'so slow ', 'as good ', 'so small ', 'more beautiful ', 'not often wrong ', 'most efficient ', 'most interesting ', 'no more ', 'there more ', 'Once more ', 'pretty bad ', 'as bad ', 'so clear ', 'very old ', 'more sensitive ', 'as dangerous ', 'so tired ', 'not worthy ', 'completely loyal ', 'not much ', \"n't likely \", 'well aware ', 'too deep ']\n",
      "There are 39 unique adjective phrases for Sandworms of Dune:  ['much more ', 'too many ', 'far more ', 'even greater ', 'only thirteen ', 'far greater ', 'even worse ', 'far superior ', 'most effective ', 'more difficult ', 'still alive ', 'entirely different ', 'kindly old ', 'not foreseen ', 'as many ', 'not possible ', 'close enough ', 'more comfortable ', 'barely able ', 'as dead ', 'more effective ', 'very much ', 'so much more ', 'even stronger ', 'most sophisticated ', 'much greater ', 'as simple ', 'not proper ', 'only seventeen ', 'Too many ', 'more traditional ', 'as important ', 'so important ', 'more valuable ', 'more powerful ', 'far worse ', 'm not afraid ', 'very real ', 'though convinced ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Get set of shared top 50 adjective phrases.\n",
    "\n",
    "dune_adjph = [word for word, freq in dune_freq_adjph.most_common(50)]\n",
    "worm_adjph = [word for word, freq in worm_freq_adjph.most_common(50)]\n",
    "shared_adjph = [word for word in dune_adjph if word in worm_adjph]\n",
    "print(f'The {len(shared_adjph)} adjective phrases that occur in both text\\'s top 50 adjective phrases are: ', shared_adjph)\n",
    "dune_unq_adjphs = [word for word in dune_adjph if word not in worm_adjph]\n",
    "worm_unq_adjphs = [word for word in worm_adjph if word not in dune_adjph]\n",
    "print(f'There are {len(dune_unq_adjphs)} unique adjective phrases for Dune: ', dune_unq_adjphs)\n",
    "print(f'There are {len(worm_unq_adjphs)} unique adjective phrases for Sandworms of Dune: ', worm_unq_adjphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dune_adjph</th>\n",
       "      <th>dune_adjs</th>\n",
       "      <th>worms_adjph</th>\n",
       "      <th>worms_adjs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(so many , 18)</td>\n",
       "      <td>(own, 245)</td>\n",
       "      <td>(so many , 30)</td>\n",
       "      <td>(own, 220)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(too much , 18)</td>\n",
       "      <td>(old, 228)</td>\n",
       "      <td>(so much , 19)</td>\n",
       "      <td>(old, 217)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(so much , 8)</td>\n",
       "      <td>(other, 211)</td>\n",
       "      <td>(no longer , 9)</td>\n",
       "      <td>(other, 199)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(as much , 8)</td>\n",
       "      <td>(more, 143)</td>\n",
       "      <td>(too much , 9)</td>\n",
       "      <td>(new, 188)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(So many , 6)</td>\n",
       "      <td>(many, 131)</td>\n",
       "      <td>(very little , 8)</td>\n",
       "      <td>(more, 185)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dune_adjph     dune_adjs        worms_adjph    worms_adjs\n",
       "0   (so many , 18)    (own, 245)     (so many , 30)    (own, 220)\n",
       "1  (too much , 18)    (old, 228)     (so much , 19)    (old, 217)\n",
       "2    (so much , 8)  (other, 211)    (no longer , 9)  (other, 199)\n",
       "3    (as much , 8)   (more, 143)     (too much , 9)    (new, 188)\n",
       "4    (So many , 6)   (many, 131)  (very little , 8)   (more, 185)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing - Adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_advph = \"ADVPH: {<RB>+<RB>}\"\n",
    "chunk_parser_adv = nltk.RegexpParser(grammar_advph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 41 adverbs that occur in both text's top 50 adverbs are:  ['not', \"n't\", 'here', 'now', 'back', 'there', 'only', 'then', 'so', 'away', 'too', 'never', 'down', 'even', 'still', 'more', 'Now', 'Then', 'yet', 'just', 'well', 'once', 'as', 'most', 'long', 'enough', 'So', 'always', 'up', 'ever', 'Not', 'again', 'far', 'very', 'already', 'forward', 'soon', 'much', 'else', 'Even', 'perhaps']\n",
      "There are 9 unique adverbs for Dune:  ['almost', 'Perhaps', 'ahead', 'Well', 'Again', 'Presently', 'Here', 'suddenly', 'Only']\n",
      "There are 9 unique adverbs for Sandworms of Dune:  ['ago', 'no', 'longer', 'also', 'simply', 'together', 'easily', 'exactly', 'finally']\n"
     ]
    }
   ],
   "source": [
    "#Adverbs\n",
    "dune_adverb_tokens = []\n",
    "for sentence in dune_tagged:\n",
    "    for word, pos in sentence:\n",
    "        if pos in ['RB', 'RBR', 'RBS']: \n",
    "            if len(word)>1:\n",
    "                dune_adverb_tokens.append(word)\n",
    "dune_freq_adverb = nltk.FreqDist(dune_adverb_tokens)\n",
    "\n",
    "worm_adverb_tokens = []\n",
    "for sentence in worm_tagged:\n",
    "    for word, pos in sentence:\n",
    "        if pos in ['RB', 'RBR', 'RBS']:\n",
    "            if len(word)>1:\n",
    "                worm_adverb_tokens.append(word)\n",
    "worm_freq_adverb = nltk.FreqDist(worm_adverb_tokens)\n",
    "summary_df['Num. Adverbs'] = [len(dune_adverb_tokens), len(worm_adverb_tokens)]\n",
    "\n",
    "dune_advs = [word for word, freq in dune_freq_adverb.most_common(50)]\n",
    "worm_advs = [word for word, freq in worm_freq_adverb.most_common(50)]\n",
    "shared_advs = [word for word in dune_advs if word in worm_advs]\n",
    "print(f'The {len(shared_advs)} adverbs that occur in both text\\'s top 50 adverbs are: ', shared_advs)\n",
    "dune_unq_advs = [word for word in dune_advs if word not in worm_advs]\n",
    "worm_unq_advs = [word for word in worm_advs if word not in dune_advs]\n",
    "print(f'There are {len(dune_unq_advs)} unique adverbs for Dune: ', dune_unq_advs)\n",
    "print(f'There are {len(worm_unq_advs)} unique adverbs for Sandworms of Dune: ', worm_unq_advs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adverb Phrases\n",
    "dune_advph_tags = []\n",
    "for sent in dune_tagged:\n",
    "    if len(sent) > 0:\n",
    "        tree = chunk_parser_adv.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'ADVPH':\n",
    "                dune_advph_tags.append(subtree)\n",
    "                \n",
    "dune_adverb_phrases = []\n",
    "for sent in dune_advph_tags:\n",
    "    temp = ''\n",
    "    for w, t in sent:\n",
    "        temp += w+ ' '    \n",
    "    dune_adverb_phrases.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm_advph_tags = []\n",
    "for sent in worm_tagged:\n",
    "    if len(sent) > 0:\n",
    "        tree = chunk_parser_adv.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'ADVPH':\n",
    "                worm_advph_tags.append(subtree)\n",
    "                \n",
    "worm_adverb_phrases = []\n",
    "for sent in worm_advph_tags:\n",
    "    temp = ''\n",
    "    for w, t in sent:\n",
    "        temp += w+ ' '    \n",
    "    worm_adverb_phrases.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dune_freq_advph = nltk.FreqDist(dune_adverb_phrases)\n",
    "worm_freq_advph = nltk.FreqDist(worm_adverb_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store in DataFrame\n",
    "advs_df = pd.DataFrame({'dune_advph': dune_freq_advph.most_common(50), \\\n",
    "    'dune_advs': dune_freq_adverb.most_common(50),\\\n",
    "    'worms_advph': worm_freq_advph.most_common(50),\\\n",
    "    'worms_advs': worm_freq_adverb.most_common(50)})\n",
    "summary_df['Num. AdvPh'] = [len(dune_advph_tags), len(worm_advph_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 18 adverb phrases that occur in both text's top 50 adverb phrases are:  ['as well ', 'not yet ', 'not even ', 'so long ', 'never again ', 'as soon ', 'far away ', 'not just ', 'soon enough ', 'long ago ', 'no longer ', 'not enough ', 'so easily ', 'long enough ', 'too much ', 'perhaps even ', 'Right now ', 'as fast ']\n",
      "There are 32 unique adverb phrases for Dune:  ['as long ', 'never before ', \"n't even \", 'right now ', 'down here ', 'As long ', 'not so ', 'far enough ', \"n't really \", 'Surely not ', 'Not even ', 'not as ', 'Very well ', 'not here ', 'here soon ', 'not very ', 'back there ', 'so well ', 'just now ', 'not quite ', 'just enough ', 'not always ', 'never once ', 'almost too ', 'not often ', 'Well then ', 'never even ', 'only now ', 'not really ', 'along presently ', 'far back ', 'here only ']\n",
      "There are 32 unique adverb phrases for Sandworms of Dune:  ['So far ', '“ Even ', 'Even so ', 'As soon ', 'so long ago ', 'so much ', 'not only ', 'so far ', 'Long ago ', 'Not yet ', 'As far ', 'm not ', '“ Now ', 'so close ', 'not far ', 'not so easily ', 'once again ', 'so swiftly ', 'Just then ', '“ Even so ', 'too long ', 'not simply ', 'Not anymore ', 'Even now ', 'so badly ', 'even now ', 'especially now ', 'not entirely ', 'far too ', 'so fast ', 'very well ', 'over again ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dune_advphs = [word for word, freq in dune_freq_advph.most_common(50)]\n",
    "worm_advphs = [word for word, freq in worm_freq_advph.most_common(50)]\n",
    "shared_advphs = [word for word in dune_advphs if word in worm_advphs]\n",
    "print(f'The {len(shared_advphs)} adverb phrases that occur in both text\\'s top 50 adverb phrases are: ', shared_advphs)\n",
    "dune_unq_advphs = [word for word in dune_advphs if word not in worm_advphs]\n",
    "worm_unq_advphs = [word for word in worm_advphs if word not in dune_advphs]\n",
    "print(f'There are {len(dune_unq_advphs)} unique adverb phrases for Dune: ', dune_unq_advphs)\n",
    "print(f'There are {len(worm_unq_advphs)} unique adverb phrases for Sandworms of Dune: ', worm_unq_advphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dune_advph</th>\n",
       "      <th>dune_advs</th>\n",
       "      <th>worms_advph</th>\n",
       "      <th>worms_advs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(as well , 18)</td>\n",
       "      <td>(not, 852)</td>\n",
       "      <td>(as well , 43)</td>\n",
       "      <td>(not, 718)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(as long , 12)</td>\n",
       "      <td>(n't, 557)</td>\n",
       "      <td>(not yet , 14)</td>\n",
       "      <td>(so, 274)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(never before , 11)</td>\n",
       "      <td>(here, 364)</td>\n",
       "      <td>(no longer , 14)</td>\n",
       "      <td>(now, 245)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(n't even , 10)</td>\n",
       "      <td>(now, 344)</td>\n",
       "      <td>(long ago , 14)</td>\n",
       "      <td>(even, 217)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(not yet , 10)</td>\n",
       "      <td>(back, 258)</td>\n",
       "      <td>(so long , 11)</td>\n",
       "      <td>(back, 214)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dune_advph    dune_advs       worms_advph   worms_advs\n",
       "0       (as well , 18)   (not, 852)    (as well , 43)   (not, 718)\n",
       "1       (as long , 12)   (n't, 557)    (not yet , 14)    (so, 274)\n",
       "2  (never before , 11)  (here, 364)  (no longer , 14)   (now, 245)\n",
       "3      (n't even , 10)   (now, 344)   (long ago , 14)  (even, 217)\n",
       "4       (not yet , 10)  (back, 258)    (so long , 11)  (back, 214)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing - Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_nounph = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "chunk_parser_noun = nltk.RegexpParser(grammar_nounph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 41 nouns that occur in both text's top 50 nouns are:  ['Paul', 'man', 'time', 'Baron', 'Leto', 'Bene', 'Yueh', 'Mother', 'Jessica', 'eyes', 'way', 'people', 'face', 'Gesserit', 'voice', 'woman', 'desert', 'spice', 'Stilgar', 'Atreides']\n",
      "The 20 nouns that occur in both text's top 50 nouns are:  ['Paul', 'man', 'time', 'Baron', 'Leto', 'Bene', 'Yueh', 'Mother', 'Jessica', 'eyes', 'way', 'people', 'face', 'Gesserit', 'voice', 'woman', 'desert', 'spice', 'Stilgar', 'Atreides']\n",
      "There are 30 unique nouns for Dune:  ['Duke', 'Hawat', 'Fremen', 'Gurney', 'Kynes', 'hand', 'men', 'Emperor', 'water', 'Chani', 'sand', 'Arrakis', 'mother', 'Halleck', 'father', 'thing', 'room', 'Feyd-Rautha', 'place', 'Sardaukar', 'Harkonnen', 'thought', 'door', 'mind', 'son', 'head', \"Muad'Dib\", 'words', 'Piter', 'rock']\n",
      "There are 30 unique nouns for Sandworms of Dune:  ['Duncan', 'Sheeana', 'Murbella', 'Face', 'machines', 'Teg', 'Erasmus', 'ghola', 'Waff', 'Omnius', 'Paolo', 'Dancers', 'Enemy', 'Tleilaxu', 'memories', 'Dancer', 'worms', 'Kwisatz', 'ships', 'Scytale', 'ship', 'years', 'Commander', 'Haderach', 'body', 'Guild', 'robot', 'machine', 'life', 'Thufir']\n"
     ]
    }
   ],
   "source": [
    "#Nouns\n",
    "dune_noun_tokens = []\n",
    "for sentence in dune_tagged:\n",
    "    for word, pos in sentence:\n",
    "        if pos in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            if len(word)>1:\n",
    "                dune_noun_tokens.append(word)\n",
    "dune_freq_noun = nltk.FreqDist(dune_noun_tokens)\n",
    "\n",
    "worm_noun_tokens = []\n",
    "for sentence in worm_tagged:\n",
    "    for word, pos in sentence:\n",
    "        if pos in ['NN', 'NNS', 'NNP', 'NNPS']: \n",
    "            if len(word)>1:\n",
    "                worm_noun_tokens.append(word)\n",
    "worm_freq_noun = nltk.FreqDist(worm_noun_tokens)\n",
    "summary_df['Num. Nouns'] = [len(dune_noun_tokens), len(worm_noun_tokens)]\n",
    "\n",
    "shared_nouns = [word for word, freq in dune_freq_noun.most_common(50)]\n",
    "shared_nouns = [word for word, freq in worm_freq_noun.most_common(50) if word in shared_nouns]\n",
    "print(f'The {len(shared_advs)} nouns that occur in both text\\'s top 50 nouns are: ', shared_nouns)\n",
    "\n",
    "\n",
    "dune_nouns = [word for word, freq in dune_freq_noun.most_common(50)]\n",
    "worm_nouns = [word for word, freq in worm_freq_noun.most_common(50)]\n",
    "shared_advs = [word for word in dune_nouns if word in worm_nouns]\n",
    "print(f'The {len(shared_nouns)} nouns that occur in both text\\'s top 50 nouns are: ', shared_nouns)\n",
    "dune_unq_nouns = [word for word in dune_nouns if word not in worm_nouns]\n",
    "worm_unq_nouns = [word for word in worm_nouns if word not in dune_nouns]\n",
    "print(f'There are {len(dune_unq_nouns)} unique nouns for Dune: ', dune_unq_nouns)\n",
    "print(f'There are {len(worm_unq_nouns)} unique nouns for Sandworms of Dune: ', worm_unq_nouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dune_nounph_tags = []\n",
    "for sent in dune_tagged:\n",
    "    if len(sent) > 0:\n",
    "        tree = chunk_parser_noun.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'NP':\n",
    "                dune_nounph_tags.append(subtree)\n",
    "                \n",
    "dune_noun_phrases = []\n",
    "for sent in dune_nounph_tags:\n",
    "    temp = ''\n",
    "    for w, t in sent:\n",
    "        temp += w+ ' '    \n",
    "    dune_noun_phrases.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm_nounph_tags = []\n",
    "for sent in worm_tagged:\n",
    "    if len(sent) > 0:\n",
    "        tree = chunk_parser_noun.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'NP':\n",
    "                worm_nounph_tags.append(subtree)\n",
    "                \n",
    "worm_noun_phrases = []\n",
    "for sent in worm_nounph_tags:\n",
    "    temp = ''\n",
    "    for w, t in sent:\n",
    "        temp += w+ ' '    \n",
    "    worm_noun_phrases.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dune_freq_nounph = nltk.FreqDist(dune_noun_phrases)\n",
    "worm_freq_nounph = nltk.FreqDist(worm_noun_phrases)\n",
    "\n",
    "nouns_df = pd.DataFrame({'dune_nounphs': dune_freq_nounph.most_common(50), \\\n",
    "    'dune_nouns': dune_freq_noun.most_common(50),\\\n",
    "    'worm_nounphs': worm_freq_nounph.most_common(50),\\\n",
    "    'worms_nouns': worm_freq_noun.most_common(50)})\n",
    "summary_df['Num. NounPh'] = [len(dune_nounph_tags), len(worm_nounph_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dune_nounphs</th>\n",
       "      <th>dune_nouns</th>\n",
       "      <th>worm_nounphs</th>\n",
       "      <th>worms_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mother , 198)</td>\n",
       "      <td>(Paul, 1690)</td>\n",
       "      <td>(“ , 941)</td>\n",
       "      <td>(Duncan, 403)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(voice , 197)</td>\n",
       "      <td>(Jessica, 894)</td>\n",
       "      <td>(” , 308)</td>\n",
       "      <td>(Sheeana, 369)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(father , 192)</td>\n",
       "      <td>(Baron, 567)</td>\n",
       "      <td>(s , 298)</td>\n",
       "      <td>(Murbella, 310)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(water , 163)</td>\n",
       "      <td>(Duke, 555)</td>\n",
       "      <td>(t , 160)</td>\n",
       "      <td>(Face, 299)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(face , 159)</td>\n",
       "      <td>(man, 481)</td>\n",
       "      <td>(’ t , 144)</td>\n",
       "      <td>(Paul, 248)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dune_nounphs      dune_nouns worm_nounphs      worms_nouns\n",
       "0  (mother , 198)    (Paul, 1690)    (“ , 941)    (Duncan, 403)\n",
       "1   (voice , 197)  (Jessica, 894)    (” , 308)   (Sheeana, 369)\n",
       "2  (father , 192)    (Baron, 567)    (s , 298)  (Murbella, 310)\n",
       "3   (water , 163)     (Duke, 555)    (t , 160)      (Face, 299)\n",
       "4    (face , 159)      (man, 481)  (’ t , 144)      (Paul, 248)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 18 noun phrases that occur in both text's top 50 noun phrases are:  ['voice ', 'face ', 'mind ', 'hand ', 'head ', 'the way ', 'something ', 'the desert ', 'time ', 'life ', 'man ', 'nothing ', 'spice ', 'way ', 'side ', 'body ', 'anything ', 'the floor ']\n",
      "There are 32 unique noun phrases for Dune:  ['mother ', 'father ', 'water ', 'the man ', 'son ', 'thought ', 'the sand ', 'attention ', 'the room ', 'sand ', 'the table ', 'the door ', 'a man ', \"m'Lord \", 'the spice ', 'fear ', 'mouth ', 'arm ', 'course ', 'a thing ', 'the basin ', 'room ', 'The man ', 'death ', 'front ', 'the troop ', 'the old woman ', 'someone ', 'a hand ', 'robe ', 'rock ', 'awareness ']\n",
      "There are 32 unique noun phrases for Sandworms of Dune:  ['“ ', '” ', 's ', 't ', '’ t ', '” “ ', 'everything ', 'melange ', 'space ', 'the thinking ', 'the ship ', '’ ', 'the ghola ', 'ghola ', 'the evermind ', 'humanity ', 'fleet ', 'the no-ship ', 'the old man ', 'the robot ', 'the machine ', 'the boy ', 'the air ', 'machine ', 'part ', 'blood ', 'tank ', 'the rest ', 'the end ', 'anyone ', 'control ', 'daughter ']\n"
     ]
    }
   ],
   "source": [
    "dune_nounphs = [word for word, freq in dune_freq_nounph.most_common(50)]\n",
    "worm_nounphs = [word for word, freq in worm_freq_nounph.most_common(50)]\n",
    "shared_nounphs = [word for word in dune_nounphs if word in worm_nounphs]\n",
    "print(f'The {len(shared_nounphs)} noun phrases that occur in both text\\'s top 50 noun phrases are: ', shared_nounphs)\n",
    "dune_unq_nounphs = [word for word in dune_nounphs if word not in worm_nounphs]\n",
    "worm_unq_nounphs = [word for word in worm_nounphs if word not in dune_nounphs]\n",
    "print(f'There are {len(dune_unq_nounphs)} unique noun phrases for Dune: ', dune_unq_nounphs)\n",
    "print(f'There are {len(worm_unq_nounphs)} unique noun phrases for Sandworms of Dune: ', worm_unq_nounphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num. Sentences</th>\n",
       "      <th>Avg. Sentence Len</th>\n",
       "      <th>Num. Adjectives</th>\n",
       "      <th>Num. AdjPh</th>\n",
       "      <th>Num. Adverbs</th>\n",
       "      <th>Num. AdvPh</th>\n",
       "      <th>Num. Nouns</th>\n",
       "      <th>Num. NounPh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dune</th>\n",
       "      <td>17668</td>\n",
       "      <td>13.420874</td>\n",
       "      <td>10575</td>\n",
       "      <td>738</td>\n",
       "      <td>8803</td>\n",
       "      <td>548</td>\n",
       "      <td>49588</td>\n",
       "      <td>29983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worms</th>\n",
       "      <td>9448</td>\n",
       "      <td>17.989733</td>\n",
       "      <td>11819</td>\n",
       "      <td>970</td>\n",
       "      <td>8217</td>\n",
       "      <td>685</td>\n",
       "      <td>37770</td>\n",
       "      <td>21538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Num. Sentences  Avg. Sentence Len  Num. Adjectives  Num. AdjPh  \\\n",
       "Dune            17668          13.420874            10575         738   \n",
       "Worms            9448          17.989733            11819         970   \n",
       "\n",
       "       Num. Adverbs  Num. AdvPh  Num. Nouns  Num. NounPh  \n",
       "Dune           8803         548       49588        29983  \n",
       "Worms          8217         685       37770        21538  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\lizzi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\lizzi\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.094, 'neu': 0.818, 'pos': 0.088, 'compound': -1.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(dune_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.119, 'neu': 0.775, 'pos': 0.106, 'compound': -1.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(worm_text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
