{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist, sent_tokenize\n",
    "from nltk.collocations import *\n",
    "from nltk.text import Text \n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/prepared_texts/dune.txt') as file:\n",
    "    dune_text = file.read()\n",
    "with open('data/prepared_texts/sandworms_clean.txt', encoding=\"utf8\", mode='r') as file:\n",
    "    worm_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'beginning', 'is', 'the', 'time', 'for', 'taking', 'the', 'most', 'delicate', 'care', 'that', 'the', 'balances', 'are', 'correct', '.'], ['This', 'every', 'sister', 'of', 'the', 'Bene', 'Gesserit', 'knows', '.'], ['To', 'begin', 'your', 'study', 'of', 'the', 'life', 'of', \"Muad'Dib\", ',', 'then', ',', 'take', 'care', 'that', 'you', 'first', 'place', 'him', 'in', 'his', 'time', ':', 'born', 'in', 'the', '57th', 'year', 'of', 'the', 'Padishah', 'Emperor', ',', 'Shaddam', 'IV', '.'], ['And', 'take', 'the', 'most', 'special', 'care', 'that', 'you', 'locate', \"Muad'Dib\", 'in', 'his', 'place', ':', 'the', 'planet', 'Arrakis', '.'], ['Do', 'not', 'be', 'deceived', 'by', 'the', 'fact', 'that', 'he', 'was', 'born', 'on', 'Caladan', 'and', 'lived', 'his', 'first', 'fifteen', 'years', 'there', '.']]\n"
     ]
    }
   ],
   "source": [
    "dune_split = nltk.sent_tokenize(dune_text)\n",
    "dune_words = [nltk.word_tokenize(sent) for sent in dune_split]\n",
    "print(dune_words[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['So', 'many', 'people', 'I', 'knew', 'in', 'the', 'past', 'are', 'not', 'yet', 'reborn', '.'], ['I', 'still', 'miss', 'them', ',', 'even', 'though', 'I', 'do', 'not', 'remember', 'them', '.']]\n"
     ]
    }
   ],
   "source": [
    "worm_split = nltk.sent_tokenize(worm_text)\n",
    "worm_words = [nltk.word_tokenize(sent) for sent in worm_split]\n",
    "print(worm_words[:2])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
